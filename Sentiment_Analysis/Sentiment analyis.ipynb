{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the required things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson import ToneAnalyzerV3\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "import glob\n",
    "from nltk import tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening up the authenticator for api\n",
    "\n",
    "authenticator = IAMAuthenticator('T9B6baxG4SgzT7ZtXa5jg-gXkV9nFZx62BmMw620kRRU')\n",
    "tone_analyzer = ToneAnalyzerV3(\n",
    "    version='2017-09-21',\n",
    "    authenticator=authenticator\n",
    ")\n",
    "\n",
    "tone_analyzer.set_service_url('https://api.us-south.tone-analyzer.watson.cloud.ibm.com/instances/07c08311-48ec-4b51-8d17-100ebe2b65f9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening up the authenticator for api\n",
    "\n",
    "authenticator = IAMAuthenticator('T9B6baxG4SgzT7ZtXa5jg-gXkV9nFZx62BmMw620kRRU')\n",
    "tone_analyzer_old = ToneAnalyzerV3(\n",
    "    version='2016-05-19',\n",
    "    authenticator=authenticator\n",
    ")\n",
    "\n",
    "tone_analyzer_old.set_service_url('https://api.us-south.tone-analyzer.watson.cloud.ibm.com/instances/07c08311-48ec-4b51-8d17-100ebe2b65f9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the file driectory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileDirectory=\"../Text_Processing/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing out the file we are evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fournobletruths.txt\n",
      "lotussutra.txt\n",
      "taoteching.txt\n",
      "upanishads.txt\n",
      "yogasutras.txt\n"
     ]
    }
   ],
   "source": [
    "# listing out the file\n",
    "FileList=(glob.glob(FileDirectory+\"*.txt\"))\n",
    "for i in FileList:\n",
    "    print(i.split(\"\\\\\")[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FileRead(a,tokenise=False):\n",
    "    \n",
    "    Dataedited=[]\n",
    "    if not tokenise:\n",
    "        with open(a, 'r',encoding='utf8') as file:\n",
    "            data = file.readlines()\n",
    "        for i in data:\n",
    "            if i =='\\n':\n",
    "                continue\n",
    "            Dataedited.append(i.replace('\\n', ''))\n",
    "    else:\n",
    "        with open(a, 'r',encoding='utf8') as file:\n",
    "            data = file.read()\n",
    "        Dataedited=(tokenize.sent_tokenize(data))\n",
    "    print(\"The document {} has {} sentences.\".format(a,len(Dataedited)))\n",
    "    return Dataedited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Analyze(text,sentence=False,new=True):\n",
    "    if new:\n",
    "        tone_analysis = tone_analyzer.tone(\n",
    "            {'body': text},sentences=sentence,\n",
    "            content_type='text/plain;charset=utf-8').get_result()\n",
    "    else: \n",
    "        tone_analysis = tone_analyzer_old.tone(\n",
    "            {'body': text},sentences=sentence,\n",
    "            content_type='text/plain;charset=utf-8').get_result()\n",
    "    return tone_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalutaion of the text file\n",
    "\n",
    "##### At first 3 files which can be evaluated by the API at one go in doucment label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document ../Text_Processing/fournobletruths.txt has 304 sentences.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'document_tone': {'tones': [{'score': 0.504269,\n",
       "    'tone_id': 'fear',\n",
       "    'tone_name': 'Fear'},\n",
       "   {'score': 0.517661, 'tone_id': 'sadness', 'tone_name': 'Sadness'},\n",
       "   {'score': 0.604644, 'tone_id': 'joy', 'tone_name': 'Joy'},\n",
       "   {'score': 0.801682, 'tone_id': 'analytical', 'tone_name': 'Analytical'}]}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fournobletruths=FileRead(FileDirectory+\"fournobletruths.txt\")\n",
    "text = fournobletruths\n",
    "\n",
    "Analyze(text,sentence=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document ../Text_Processing/taoteching.txt has 1034 sentences.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'document_tone': {'tones': [{'score': 0.558764,\n",
       "    'tone_id': 'sadness',\n",
       "    'tone_name': 'Sadness'},\n",
       "   {'score': 0.520081, 'tone_id': 'joy', 'tone_name': 'Joy'},\n",
       "   {'score': 0.691386, 'tone_id': 'analytical', 'tone_name': 'Analytical'}]}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taoteching=FileRead(FileDirectory+\"taoteching.txt\")\n",
    "text = taoteching\n",
    "\n",
    "Analyze(text,sentence=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document ../Text_Processing/upanishads.txt has 1326 sentences.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'document_tone': {'tones': [{'score': 0.669667,\n",
       "    'tone_id': 'joy',\n",
       "    'tone_name': 'Joy'},\n",
       "   {'score': 0.760886, 'tone_id': 'analytical', 'tone_name': 'Analytical'}]}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upanishads=FileRead(FileDirectory+\"upanishads.txt\",False)\n",
    "text = upanishads\n",
    "\n",
    "Analyze(text,sentence=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For document which are long and API can't do analyis at one go\n",
    "\n",
    "###### We are taking a big sample sentences from the text without replacent and doing sentiment analyis on them . \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting out seed for the results reproducibility \n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document ../Text_Processing/yogasutras.txt has 1181 sentences.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'document_tone': {'tones': [{'score': 0.526717,\n",
       "    'tone_id': 'anger',\n",
       "    'tone_name': 'Anger'},\n",
       "   {'score': 0.773549, 'tone_id': 'analytical', 'tone_name': 'Analytical'}]}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "yogasutras=FileRead(FileDirectory+\"yogasutras.txt\",True)\n",
    "text =list(np.random.choice(yogasutras,500,replace=False))\n",
    "\n",
    "Analyze(text,sentence=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document ../Text_Processing/lotussutra.txt has 9093 sentences.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'document_tone': {'tones': [{'score': 0.586672,\n",
       "    'tone_id': 'joy',\n",
       "    'tone_name': 'Joy'},\n",
       "   {'score': 0.523097, 'tone_id': 'analytical', 'tone_name': 'Analytical'}]}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lotussutra=FileRead(FileDirectory+\"lotussutra.txt\")\n",
    "text = text =list(np.random.choice(lotussutra,1500,replace=False))\n",
    "Analyze(text,sentence=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentiments are of two type\n",
    "* Emotional tones: Angry, sadness,joy, fear. \n",
    "* Language tones: Aanlytical, convident and tentative. \n",
    "\n",
    "Link to the documentaion of the api: https://cloud.ibm.com/apidocs/tone-analyzer?code=python#introduction "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}